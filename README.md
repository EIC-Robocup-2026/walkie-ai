# Walkie-AI

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö AI Agent ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (Multimodal) ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Voice), ‡∏†‡∏≤‡∏û (Vision) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö (Interaction) ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö **Modular Architecture** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ (Scalability) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤ (Maintainability)

## üìÇ Project Structure Overview

‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ñ‡∏π‡∏Å‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Separation of Concerns) ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

```text
project_root/
‚îú‚îÄ‚îÄ config/             # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö (Configuration)
‚îú‚îÄ‚îÄ data/               # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Local (Database files, temp images)
‚îú‚îÄ‚îÄ src/                # Source code ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
‚îÇ   ‚îú‚îÄ‚îÄ agent/          # [The Brain] Logic ‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
‚îÇ   ‚îú‚îÄ‚îÄ database/       # [Memory] ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Persistence
‚îÇ   ‚îú‚îÄ‚îÄ interface/      # [I/O] ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö/‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á (ASR/TTS)
‚îÇ   ‚îú‚îÄ‚îÄ tools/          # [Skills] ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡πÄ‡∏®‡∏© (RAG, Navigation)
‚îÇ   ‚îú‚îÄ‚îÄ vision/         # [Eyes] ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û (Image Model)
‚îÇ   ‚îî‚îÄ‚îÄ utils/          # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
‚îú‚îÄ‚îÄ tests/              # Unit tests
‚îú‚îÄ‚îÄ main.py             # Entry point ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
‚îî‚îÄ‚îÄ requirements.txt    # Python dependencies
````

-----

## üèóÔ∏è Module Descriptions

‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Module ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô `src/` ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö System Diagram:

### 1\. `src/agent/` (The Brain)

‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô "‡∏™‡∏°‡∏≠‡∏á" ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Orchestrator ‡∏Ñ‡∏≠‡∏¢‡∏£‡∏±‡∏ö Input ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ

  * **Core Role:** ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å ASR, ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Tools, ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà TTS
  * **Files:**
      * `core.py`: Main agent with LangChain ReAct framework
      * `memory.py`: Conversation history and context management
      * `state.py`: Agent status tracking (idle, processing, speaking)
      * `mcp_server.py`: MCP server exposing agent as tools

### 2\. `src/interface/` (Input/Output)

‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡πÇ‡∏•‡∏Å‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (Human-Computer Interaction)

  * **ASR (Automatic Speech Recognition):** ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
  * **TTS (Text-to-Speech):** ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î
  * **Files:** `asr/`, `tts/`

### 3\. `src/tools/` (Capabilities)

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà Agent ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ (Function Calling)

  * **`rag/` (Retrieval-Augmented Generation):** ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô
  * **`navigation/`:** ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á (Planner/Controller)
  * **`action_policy/`:** ‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠ Logic ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á

### 4\. `src/vision/` (The Eyes)

‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û ‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏™‡∏£‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

  * **Image Model:** ‡πÉ‡∏ä‡πâ Model ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô Vector (Embeddings) ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô
  * **Flow:** Image Capture -\> Image Model -\> Database

### 5\. `src/database/` (Memory & Storage)

‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏ß‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Diagram

  * **Schema:** ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (Pydantic Models) ‡πÄ‡∏ä‡πà‡∏ô:
      * `Coordinate` / `Pose`
      * `Semantic Location` (e.g., "Kitchen")
      * `Image Embeddings` (Vector search)
  * **Connection:** ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö SQL ‡∏´‡∏£‡∏∑‡∏≠ Vector Database

-----

## üöÄ Getting Started

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ **Conda** environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ dependencies

### Prerequisites

  * Python 3.11+
  * Conda (Miniconda or Anaconda)
  * API Keys: OpenAI, ElevenLabs, Google Cloud

### Installation

1.  Clone repository:

    ```bash
    git clone <your-repo-url>
    cd walkie-ai
    ```

2.  Create Conda environment:

    ```bash
    conda create -n eic python=3.11 -y
    conda activate eic
    ```

3.  Install dependencies:

    ```bash
    pip install -e .
    ```

4.  Environment Setup:
    Copy `.env.example` to `.env` and add your API keys:

    ```bash
    cp .env.example .env
    # Edit .env with your keys
    ```

### Usage

**Interactive Mode:**
```bash
python main.py --mode interactive
```

**Text Command:**
```bash
python main.py --mode text --command "Your command here"
```

**Voice Mode:**
```bash
python main.py --mode voice --audio input.wav --output response.mp3
```

**MCP Server (Recommended for integration):**
```bash
python -m src.agent.mcp_server
# Or test it:
python test_mcp_server.py
```

-----

## üõ†Ô∏è Tech Stack

  * **Language:** Python 3.11
  * **Agent Framework:** LangChain (ReAct agent)
  * **LLM:** OpenAI GPT-4
  * **TTS:** ElevenLabs
  * **STT:** Google Cloud Speech-to-Text
  * **Audio Processing:** Silero VAD, sounddevice
  * **Integration:** MCP (Model Context Protocol)
